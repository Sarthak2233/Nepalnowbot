from langchain.schema import SystemMessage, HumanMessage
from backend.parse import create_faiss_index
from langchain_google_genai import (
    ChatGoogleGenerativeAI,
    HarmBlockThreshold,
    HarmCategory,
)


def chat_gemini(search_results: list, query: str) -> str:
    # Combine the search results into one string to pass to the model
    search_results_text = "\n".join([result.page_content for result in search_results])

    prompt = f"""
        You have to act as an assistant in a friendly and professional manner.
        Observe the details from the following search results:

        {search_results_text}

        if the information is not complete then answer the most relevant or say i am unable to answer.

        Analyze user language and if possible reply in that language otherwise reply in English language.
        Remember the recent questions and answer according to them.
        Don't reply the personal and rough word query.

        Now, respond to the user's query as accurately as possible.
        """

    # Initialize the Gemini model
    llm = ChatGoogleGenerativeAI(
        model="models/gemini-1.5-pro",
        temperature=0.3,
        max_tokens=500,
        timeout=None,
        max_retries=2,
        safety_settings={
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        },
    )

    try:
        # Create the conversation context with SystemMessage and HumanMessage
        conversation = [
            SystemMessage(content=prompt),  # System message with the context
            HumanMessage(content=f"Query: {query}")  # User's query
        ]

        # Generate a response using Gemini
        completion = llm.generate([conversation])

        # Extract and return the content of the first generated message
        if completion.generations and completion.generations[0]:
            response_content = completion.generations[0][0].message.content
            return response_content
        else:
            return "No response generated by the model."

    except Exception as e:
        print(f"Error calling Gemini API: {e}")
        return "Sorry, there was an error processing your request."

search_results = """"""
# Continuous interaction loop
while True:
    # Ask the user for a query
    query = input("\nUser: ")

    # Exit the loop if the user types 'exit' or 'bye'
    if query.lower() in ['exit']:
        print("Exiting the chatbot. Goodbye! Have a great day!")
        break

    # Perform a similarity search with the query (top 2 results)
    search_results = create_faiss_index(search_results).similarity_search(query, k=4)

    # Call the chat_gemini function and print the response
    response = chat_gemini(search_results, query)
    print("\nAI:", response)
